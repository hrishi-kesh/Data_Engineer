import os
import sys

# Set Spark and Hadoop Paths
os.environ["SPARK_HOME"] = "C:/spark"
os.environ["HADOOP_HOME"] = "C:/hadoop"

# Add PySpark and Py4J to system path
sys.path.append("C:/spark/python")
sys.path.append("C:/spark/python/lib/py4j-0.10.9.7-src.zip")  # Adjust version

# Now, try importing PySpark
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("JupyterTest").getOrCreate()
print(spark.version)