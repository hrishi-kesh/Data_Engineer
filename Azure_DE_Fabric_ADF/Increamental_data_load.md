# ğŸ”„ Incremental Data Load in Azure Data Factory

## ğŸ“º Learning Resource
- **Tutorial**: 1. "Azure Data Engineer Project | Incremental Data Load in Azure Data Factory"
- **Focus**: Implementation of incremental data load patterns in ADF

## ğŸ¯ Process Overview
Learn how to efficiently transfer new/updated data using Azure Data Factory pipelines.

## ğŸ› ï¸ Implementation Steps

### 1. Initial Setup
- ğŸ”— **Configure Linked Services**
    - Connect ADF to source SQL Database
    - Connect ADF to target SQL Database

- ğŸ“Š **Define Datasets**
    - Source: `orders` table
    - Target: `order_final` table

### 2. Pipeline Development
- ğŸ—ï¸ **Create Basic Pipeline Structure**

- ğŸ” **Configure Lookup Activity** (`Lookup1`)
    ```sql
    SELECT MAX(inserttime) AS date1 FROM order_final
    ```
    > Retrieves latest watermark timestamp

- ğŸ“ **Setup Copy Data Activity**
    ```sql
    SELECT order_id, name, inserttime 
    FROM orders 
    WHERE inserttime > '@{activity('Lookup1').output.firstRow.date1}'
    ```
    > Copies only new/modified records

### 3. Production Deployment
- â° **Set Up Triggers**: Schedule automated runs
- ğŸ“Š **Monitor Pipeline**: Track execution & handle errors

## ğŸ‰ Success Criteria
- âœ… Only new/modified data transferred
- âœ… Efficient resource utilization
- âœ… Automated execution
